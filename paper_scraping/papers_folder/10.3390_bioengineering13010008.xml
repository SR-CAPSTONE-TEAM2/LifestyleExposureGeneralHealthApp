<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE collection SYSTEM "BioC.dtd"><collection><source>BioC-API</source><date>20260212</date><key>collection.key</key><document><id>PMC12838207</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3390/bioengineering13010008</infon><infon key="article-id_pmc">PMC12838207</infon><infon key="article-id_publisher-id">bioengineering-13-00008</infon><infon key="elocation-id">8</infon><infon key="issue">1</infon><infon key="kwd">inflammatory bowel disease colonoscopy images semi-supervised learning contrastive learning</infon><infon key="license">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license.</infon><infon key="name_0">surname:Lin;given-names:Kechen</infon><infon key="name_1">surname:Ruan;given-names:Guangcong</infon><infon key="name_2">surname:Zou;given-names:Xiaoyang</infon><infon key="name_3">surname:Nian;given-names:Yongjian</infon><infon key="name_4">surname:Wei;given-names:Yanling</infon><infon key="name_5">surname:Zheng;given-names:Guoyan</infon><infon key="name_6">surname:Meng;given-names:Nan</infon><infon key="name_7">surname:Cheung;given-names:Jason Pui Yin</infon><infon key="name_8">surname:Shao;given-names:Junming</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">13</infon><infon key="year">2026</infon><offset>0</offset><text>Subclass-Aware Contrastive Semi-Supervised Learning for Inflammatory Bowel Disease Classification from Colonoscopy Images</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>122</offset><text>Inflammatory bowel disease (IBD) includes Crohn’s disease (CD) and ulcerative colitis (UC). The accurate classification of IBD from colonoscopy images is critical for diagnosis and treatment. However, the lack of labeled data poses a major challenge for developing deep learning-based IBD classification approaches. Recently, pseudo-labeling-based semi-supervised learning methods offer a promising solution in leveraging both labeled and unlabeled data to improve classification performance. Nevertheless, due to significant intra-class variability and the subtle inter-class differences in IBD colonoscopy images, pseudo-labels are often inaccurate, which results in confirmation bias and suboptimal performance. To address this challenge, a Subclass-Aware Contrastive Semi-Supervised Learning method, referred to as SACSSL, is proposed for accurate IBD classification by integrating a subclass-aware contrastive module into a pseudo-labeling-based semi-supervised framework, e.g., FixMatch. Specifically, unlabeled samples are first partitioned into confident and uncertain samples according to the confidence of pseudo-labels. An instance-level contrastive loss is then applied to uncertain samples, aiming to mitigate confirmation bias. Furthermore, intra-class heterogeneity is captured by introducing a set of prototypes for each subclass and assigning confident samples to these prototypes to form fine-grained subclasses, and supervised contrastive loss is applied to promote intra-subclass clustering, thereby enhancing inter-class separability while preserving intra-class diversity. Our method is evaluated on two datasets, i.e., an in-house collected Daping dataset for IBD classification and a publicly available LIMUC dataset for UC severity grading. On both datasets, our method achieves state-of-the-art performance under the semi-supervised setting. Specifically, with only 20% labeled data, the proposed method reaches an overall accuracy of 93.2% and an F1-score of 80.1% on the Daping dataset, which is close to the fully supervised upper bound (94.0% accuracy and 80.8% F1-score), and it achieves an overall accuracy of 76.4% and an F1-score of 68.9% on the LIMUC dataset. Comprehensive experimental results demonstrate the effectiveness of our method for semi-supervised colonoscopy image classification.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>2452</offset><text>1. Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2468</offset><text>Inflammatory bowel disease (IBD), including Crohn’s disease (CD) and ulcerative colitis (UC), has emerged as a global health concern in recent years. Recent epidemiological studies have shown that IBD has evolved across different global regions with increasing incidence in newly industrialized countries. The symptoms of IBD includes diarrhea, abdominal pain, and rectal bleeding, which can seriously affect patients’ quality of life. The diagnosis of IBD relies on comprehensive evaluation using endoscopic, histological, clinical, and radiological criteria. In practice, colonoscopy plays a vital role in the diagnosis, treatment, and follow-up monitoring of IBD. However, since UC and CD have a similar appearance in colonoscopy, endoscopists may misinterpret the images due to limited experience or unconscious bias, resulting in misdiagnosis, missed diagnoses, and delayed treatment. Therefore, it is necessary to improve the IBD classification accuracy to better distinguish between UC and CD in colonoscopy images, which would enhance patients’ quality of life and equip endoscopists with tools that increase both the accuracy and efficiency of clinical care.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3642</offset><text>With the rapid development of artificial intelligence, data-driven deep learning-based approaches have demonstrated impressive performance in computer-aided endoscopic tasks. However, the lack of labeled data presents a major challenge for deep learning-based IBD classification. Semi-supervised learning, which leverages both labeled and unlabeled data, provides a promising solution to this problem. Commonly adopted semi-supervised learning paradigms in endoscopic classification are pseudo-labeling and consistency regularization. In particular, pseudo-labeling-based methods assign pseudo-labels to unlabeled data based on model predictions, which are then used for supervised training. Consistency regularization assumes that different perturbed or augmented versions of the same input should yield consistent predictions. Building on these two paradigms, previous studies combine pseudo-labeling and consistency regularization techniques to achieve impressive performance. However, high intra-class heterogeneity and low inter-class variance among IBD colonoscopy images may lead to inaccurate pseudo-labels. When the model overfits to these inaccurate pseudo-labels, performance degrades due to confirmation bias. Recently, inspired by self-supervised learning approaches, Yang et al. designed a class-aware contrastive module to learn more separated feature clusters at the class-level to improve model predictions. This method demonstrates promising performance on the semi-supervised classification of natural images. However, under the context of the IBD semi-supervised classification task, it overlooks intra-class heterogeneity. Forcing highly diverse samples within the same class to learn overly aligned representations may suppress fine-grained semantic information, leading to suboptimal classification performance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5477</offset><text>To explicitly model intra-class heterogeneity, previous works have attempted to decompose each class into multiple subclasses via clustering and then train classifiers with subclass-aware supervision. However, these methods require all samples to have class labels, thus failing to leverage abundant unlabeled data. Additionally, prototype-based learning has been widely adopted in clustering-based self-supervised learning approaches such as SwAV and DeepCluster. These methods learn representations by contrasting predicted cluster assignments of correlated views of the same image. To aggregate samples together while avoiding collapsed solutions, they employ simple clustering-based pseudo-labeling algorithms (e.g., K-means clustering or the Sinkhorn–Knopp algorithm) to generate assignments. Without access to labeled data, these self-supervised methods learn prototypes that do not encode explicit class information, resulting in suboptimal performance when directly applied to classification tasks.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6486</offset><text>A novel subclass-aware contrastive semi-supervised learning framework for accurate colonoscopy image classification is introduced, which explicitly exploits abundant unlabeled samples to effectively capture intra-class heterogeneity.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6720</offset><text>A novel subclass-aware contrastive module that adaptively handles unlabeled data with different contrastive objectives based on pseudo-label confidence is designed, aiming to suppress confirmation bias for uncertain samples and discover fine-grained subclasses for confident samples, thereby enhancing class separability while capturing intra-class variations.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7081</offset><text>Comprehensive experiments are conducted on two colonoscopy image datasets, i.e., an in-house collected Daping dataset for IBD classification and a publicly available LIMUC dataset for UC severity grading. The experimental results demonstrate that the proposed method achieves superior classification performance compared to state-of-the-art semi-supervised learning methods on both datasets.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7473</offset><text>To address these challenges, a Subclass-Aware Contrastive Semi-Supervised Learning (SACSSL) framework is proposed, which incorporates a carefully designed subclass-aware contrastive module into a pseudo-labeling-based semi-supervised learning paradigm (i.e., FixMatch). The key innovation of the proposed subclass-aware contrastive module lies in explicitly exploiting abundant unlabeled samples to effectively capture intra-class heterogeneity. Instead of treating each class as a single compact cluster, multiple prototypes per class are introduced to automatically discover fine-grained subclasses in the embedding space. By associating unlabeled samples with different prototypes and enforcing subclass-aware contrastive objectives, the proposed module enhances intra-subclass compactness while preserving rich intra-class diversity, leading to more discriminative and semantically meaningful representations. Specifically, in the subclass-aware contrastive module, unlabeled data are partitioned into confident and uncertain sets based on the maximum probability of their pseudo-labels. Because confident samples with high prediction confidence are more likely to provide reliable supervision, while uncertain samples with low prediction confidence tend to introduce noise and thus require cautious handling, different contrastive objectives are designed to different subsets of unlabeled data to fully exploit their potential. Specifically, an instance-level contrastive loss is applied to encourage the separation of uncertain samples from all other samples in the embedding space to mitigate the confirmation bias in the semi-supervised training. To model the intra-class heterogeneity of IBD images, each class is represented by a set of prototypes in the embedding space. Confident samples are assigned to different prototypes within the same class to form fine-grained subclasses, which allows the supervised contrastive loss to promote intra-subclass clustering among confident samples, effectively enhancing class separability while preserving fine-grained intra-class semantics. The main contributions of the proposed method can be summarized as follows:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>9642</offset><text>2. Related Works</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>9659</offset><text>2.1. Deep Learning-Based IBD Diagnosis Applications</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9711</offset><text>A variety of deep learning-based approaches have been developed to assist the IBD diagnosis across different modalities.. In colonoscopy, Ruan et al. developed a deep learning model based on a deep convolutional neural network to distinguish between UC and CD using over 47,000 endoscopic images from a private dataset, achieving better classification performance compared to junior endoscopists. Similarly, Mauricio et al. developed interpretable deep learning models to classify UC and CD with visualization modules that highlight disease-relevant regions, thereby enhancing clinical trust. In another study, Stidham et al. evaluated the performance of Inception V3, a 159-layer CNN, on the task of endoscopic severity grading of UC, showing performance on par with experienced human reviewers. To address the class imbalance commonly observed in IBD-related classification tasks, recent works have proposed specialized techniques, such as high-frequency balancing and augmentation or class distance weighted loss functions to improve minority-class recognition.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10776</offset><text>Beyond colonoscopy, Klang et al. employed EfficientNet-B5 for detecting strictures from capsule endoscopy images in CD, showing robust generalization capability in multi-center datasets. Similarly, Malik et al. achieved 99.45% accuracy in multi-class classification of UC, polyps, and dyed-lifted polyps from wireless capsule endoscopy (WCE) images using hybrid CNN-GRU architectures. Extending to panenteric capsule endoscopy, Brodersen et al. demonstrated that AI-assisted PCE can effectively differentiate CD, UC, and cancer in a prospective multi-center study, significantly reducing image review time using the AXARO® framework. More recently, Das et al. developed a deep learning model for classifying IBD activity grades from histopathology whole slide images, achieving robust diagnostic performance that could assist pathologists in consistent IBD assessment.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11646</offset><text>However, these approaches heavily rely on large amount of expert-annotated data that is often difficult to acquire due to the time-consuming annotation process and expertise knowledge requirement.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>11843</offset><text>2.2. Semi-Supervised Learning in Endoscopic Image Analysis</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11902</offset><text>Semi-supervised learning has emerged as a promising paradigm by leveraging both labeled and unlabeled data to improve the IBD classification performance, thereby alleviating the heavy reliance on large amount of expert-annotated data. Previous studies have explored the application of semi-supervised learning in endoscopic image analysis, primarily employing two techniques: pseudo-labeling and consistency regularization. Guo et al. proposed a semi-supervised learning framework with an Adaptive Aggregated Attention module for automatic wireless capsule endoscopy image classification, significantly outperforming supervised baselines. Muruganantham et al. developed ACT-WISE, which employed a teacher–student framework to enforce consistency under perturbations of unlabeled wireless capsule endoscopy images, and integrated active learning for improving label efficiency. There exist other works that combine pseudo-labeling and consistency regularization techniques. Notably, FixMatch integrated both techniques by applying weak and strong augmentations to each unlabeled image, where predictions from the weakly augmented image served as pseudo-labels for training on the strongly augmented image, which has shown impressive classification performance in natural image benchmarks. This has been extended by previous studies to semi-supervised endoscopic image classification. For example, Huang et al. proposed the class-specific distribution alignment strategy to improve the quality of pseudo-labels when training on highly imbalanced datasets and demonstrate its effectiveness in endoscopic image classification.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13527</offset><text>Beyond consistency regularization and pseudo-labeling, recent studies have explored incorporating auxiliary tasks into semi-supervised frameworks to enhance representation learning. These tasks can be employed either by self-supervised pretraining to provide better model initialization or incorporating auxiliary objectives into the semi-supervised framework to refine feature representations. For example, Wang et al. proposed a semi-supervised framework that is first pretrained with self-supervised learning on a large unlabeled dataset and then fine-tuned on a limited labeled dataset, achieving promising performance on classifying colorectal neoplasia from narrow-band imaging colonoscopic images under low-label settings. Golhar et al. proposed a novel semi-supervised method that combines an unsupervised jigsaw puzzle solving task with supervised learning, which has achieved promising results in classifying lesions from colonoscopy images. Yang et al. incorporate a class-aware contrastive module into the pseudo-labeling-based semi-supervised framework. Specifically, they apply class-level clustering to in-distribution samples and instance discrimination contrastive loss to out-of-distribution samples, and they achieve impressive performance on natural image benchmarks.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>14815</offset><text>3. Materials and Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14840</offset><text>In this work, we consider a semi-supervised IBD classification problem from colonoscopy images. Specifically, for a C-class classification problem, let the input image be  and the ground truth label be , where H and W denote the height and width of the image, and 3 corresponds to the RGB channels. Let  and  be the labeled and unlabeled datasets, respectively, where  and  are the labeled images and the corresponding labels, and  are the unlabeled images.  and  are the number of samples in the labeled dataset and the unlabeled dataset, respectively, where . We employ a visual encoder  to obtain feature representation. We further attach a prediction head  to the visual encoder  to produce distribution over classes, i.e., . Moreover, we attach a projection head  to the visual encoder  to obtain low-dimensional features in embedding space for contrastive learning, i.e., , where z represents the projected representation of input image x. At each epoch, we first randomly shuffle the labeled dataset  and the unlabeled dataset , and then split each dataset into a series of smaller data chunks. We sample one data chunk from the labeled dataset and one from the unlabeled dataset at each iteration. Let  be a data batch which has B samples in total, containing labeled data  and unlabeled data  where  and  are the number of labeled samples and the unlabeled samples in the batch, respectively.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16242</offset><text>A schematic illustration of the proposed SACSSL is presented in Figure 1. The framework comprises a visual encoder , a prediction head  and a projection head , which are integrated with a semi-supervised learning module and a novel subclass-aware contrastive module. Within the framework, we first apply a weak augmentation  to all images and two strong augmentations  and  to the unlabeled images. All augmented images are then passed through the visual encoder to extract features, which are subsequently optimized by two complementary modules. In the semi-supervised learning module, ground-truth labels supervise the weakly augmented labeled samples, while pseudo-labels generated from weakly augmented unlabeled images serve as supervision targets for their first strongly augmented counterparts. Subsequently, embeddings from paired strongly augmented unlabeled images are extracted via the projection head  and jointly processed by the subclass-aware contrastive module. In the subclass-aware contrastive module, confident and uncertain samples are identified based on pseudo-labels, and then tailored contrastive learning strategies are applied to each group to preserve fine-grained intra-class semantics while enhancing inter-class separability, as detailed in Section 3.2. These components are jointly optimized in an end-to-end manner with three objectives: a supervised loss , an unsupervised loss , and a subclass-aware contrastive loss . Details will be presented below. For a quick reference, we list common symbols used in this section in Table 1.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17807</offset><text>3.1. Semi-Supervised Learning Module</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17844</offset><text>Following FixMatch, the semi-supervised learning module consists of two cross-entropy loss terms: a supervised loss  applied to labeled data and an unsupervised loss  applied to unlabeled data.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18038</offset><text>For each labeled sample  (where , we are aiming at minimizing the cross-entropy loss between the model’s predicted distribution over classes on the weakly augmented view  and the corresponding ground truth label . Accordingly, the supervised loss  is defined as where  denotes the cross-entropy function.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18345</offset><text>For each unlabeled sample  (where ), we generate a weak augmented view  and a strong augmented view . The soft pseudo-label is derived by computing the model’s predicted distribution over classes on the weakly augmented view, i.e., . Subsequently, the hard pseudo-label is obtained by taking the class with the highest predicted probability, i.e., . To ensure quality of the pseudo-label, we retain only those samples whose highest predicted probability exceeds a threshold T for training. Formally, we define a binary indicator: , where  is the indicator function that returns 1 if the condition holds and 0 otherwise. Finally, we aim to minimize the cross-entropy loss between the hard pseudo-label  and the model’s predicted distribution over classes on the strongly augmented view, i.e., . Accordingly, the unsupervised loss  is defined as</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>19193</offset><text>3.2. Subclass-Aware Contrastive Module</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19232</offset><text>The limited visual difference between different classes and the significant appearance variability within the same class lead to inaccurate pseudo-labels, which post great challenges for accurate IBD classification. To meet these challenges, we introduce a subclass-aware contrastive module to regularize the low-dimensional feature embedding space. A schematic illustration of the proposed subclass-aware contrastive module is presented in Figure 2. In the subclass-aware contrastive module, confident and uncertain samples are first identified based on the pseudo-labels. To capture intra-class heterogeneity, each class is represented by a set of online-updated prototypes. Confident samples are then assigned to these prototypes to form subclasses, and distinct contrastive objectives are respectively applied to confident and uncertain samples in the embedding space. Specifically, uncertain samples are optimized with an instance-level contrastive loss to reduce the impact of inaccurate pseudo-labels. For confident samples, a subclass-level contrastive loss is designed to encourage subclass-level clustering, enabling the model to preserve fine-grained intra-class semantics and enhance inter-class separability. A step-by-step explanation of the details is presented below.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20516</offset><text>For each unlabeled sample , we generate a second strongly augmented view  in addition to the first view . We then construct two data batches composed of the strong augmented views and the corresponding soft pseudo-labels, which are defined as  and . Subsequently, these batches are merged into a multi-view batch , which contains  samples. For notational simplicity, we denote the multi-view batch as , where  represents a strongly augmented view and  is its corresponding soft pseudo-label. Subsequently, all images in the multi-view batch are fed through the visual encoder  and the projection head  to produce the embedding set , where each embedding is -normalized. Next, let  be the set of indices of all augmented samples within the multi-view batch. We partition I into confident and uncertain sets based on the confidence of the corresponding pseudo-label:  , where  is a scalar hyperparameter that determines whether a sample should be considered as a confident sample. This separation allows the model to employ the instance-level contrastive loss  and the subclass-level contrastive loss  anchored, respectively, at uncertain and confident samples. In the following, we describe the design of the instance-level and the subclass-level contrastive losses in detail.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>21793</offset><text>3.2.1. Instance-Level Contrastive Loss</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21832</offset><text>To mitigate the confirmation bias during training, we employ an instance-level contrastive loss on uncertain samples, following the formulation in SimCLR, where each image instance is treated as its own class. Specifically, taking an anchor embedding from the uncertain sample  (where ) and another embedding  (where ) for example, we regard the embedding pair  to be positive only when  is the embedding from the alternative augmented view of the same original image, which is denoted as . Otherwise, the embedding pair is considered to be negative. Subsequently, the instance-level contrastive loss  is formulated as where  is a temperature parameter.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>22486</offset><text>3.2.2. Prototype-Based Subclass-Level Contrastive Loss</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22541</offset><text>To capture fine-grained intra-class semantics and improve inter-class separability, we propose a prototype-based subclass-level contrastive learning strategy. Confident samples are assigned to a set of class-specific prototypes, effectively forming subclasses. Inspired by, we designed a supervised contrastive loss to encourage samples within each subclass to cluster closely while remaining distinct from other subclasses. The details about the prototype-based subclass-level contrastive loss are presented below.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23057</offset><text>Online Prototype Assignment. For each class , we incorporate K subclass prototypes  to represent this class, where each prototype  is an -normalized vector in the embedding space. Let  denote the indices of confident samples in the multi-view batch that are predicted as class c, i.e., , and let  denote the number of samples in . We enumerate these indices as . The corresponding confident samples are collected as . Our objective is to assign the samples in  to the K subclass prototypes of class c. We denote the sample-to-prototype mapping as  where each  represents the assignment probabilities of sample  over the K prototypes.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23691</offset><text>Concretely, given the embedding matrix  where each  is the -normalized embedding of ,  is optimized by solving an optimal transport problem that maximizes the cosine similarity between  and the prototypes, i.e.,  with an entropy regularization term. The optimization objective is defined as where  is a parameter controls the smoothness of , while  and  denote all of the K-dimension and -dimension vectors, respectively. The unique assignment constraint, i.e., , ensures that each sample is assigned to one prototype. The equipartition constraint, i.e., , enforces each prototype is selected at least  times on average in the multi-view batch, which prevents the trivial solution. The solution to this optimization problem is where  and  are renormalization vectors, which can be updated by a few steps of the Sinkhorn–Knopp algorithm.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24530</offset><text>Prototype-based Subclass-level Contrastive Loss. With the assignment probability matrix , we online group the samples  into K prototypes  within class c. After processing all confident samples in the multi-view batch, each confident sample  (where ) is assigned to -th prototype of class , where  and .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24833</offset><text>Subsequently, taking an anchor embedding from a confident sample  (where ) and an another embedding  (where ) for example, we regard the embedding pair  to be positive if one of the following conditions holds: (1)  is the embedding from the alternative augmented view of the same original image, which is denoted as , or (2)  corresponds to a different original image but is assigned to the same prototype as . Formally, we define the set of cross-image positive indices as . Otherwise, the embedding pair is considered to be negative. To weaken the bias of enforcing alignment between samples with potentially incorrect pseudo-labels, we introduce a confident weight  for positive pairs from different images. Specifically, for a positive pair  where , the confident weight is defined as .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25624</offset><text>We calculate contrastive loss  anchored at  as follows: where  denotes the temperature parameter.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25722</offset><text>The prototype-based subclass-level contrastive loss  is defined by where  is the number of positive samples for the i-th sample in the multi-view batch.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25875</offset><text>Prototype Update. At the training stage, the prototypes  are updated in an online manner using the embeddings assigned to them. Specifically, after each iteration, each prototype is updated based on the normalized center of its assigned embeddings, which can be formulated as where  represents the set of embeddings assigned to prototype  in the multi-view batch, and  is the momentum coefficient.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>26273</offset><text>3.2.3. Subclass-Aware Contrastive Loss</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26312</offset><text>The subclass-aware contrastive loss  is defined as the average of losses anchored at the confident and the uncertain samples over the multi-view batch.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>26464</offset><text>3.3. Overall Objective Function</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26496</offset><text>The overall objective function of the proposed method is where  and  are weighting parameters for the unsupervised loss  and the subclass-aware contrastive loss , respectively.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>26673</offset><text>4. Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>26684</offset><text>4.1. Experimental Setting</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26710</offset><text>Study approval. This retrospective study was approved by the ethics committee of Daping Hospital affiliated with Army Military Medical University (No. 2018-137). A waiver of informed consent was granted by the same ethics committee. In addition, the clinical study registration number is ChiCTR2100043278. The study complies with the Declaration of Helsinki.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27069</offset><text>Datasets. We conduct comprehensive experiments on two colonoscopy image datasets: an in-house collected Daping dataset for IBD classification and a publicly available LIMUC dataset for UC severity grading.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27275</offset><text>Daping dataset: The Daping dataset comprises 17,161 colonoscopy images from 599 patients collected at the Department of Gastroenterology, Daping Hospital, Army Medical University, between January 2018 and November 2020. Following quality control, images were independently annotated by two experienced gastroenterologists with disagreements resolved by a third expert. Specifically, the Daping dataset consists of three categories, including 1093 CD images, 3379 UC images, and 12,689 normal mucosa images.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27782</offset><text>LIMUC dataset: The LIMUC dataset consists of 11,276 colonoscopy images collected from 564 patients. The images are annotated by experienced gastroenterologists according to the Mayo Endoscopic Score (MES) and are distributed across four severity grades, including 6105 images with MES 0, 3052 images with MES 1, 1254 images with MES 2, and 865 images with MES 3.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28145</offset><text>We randomly split the dataset by patient into training and testing sets with a ratio of 8:2, ensuring that no images from the same patient appear in both sets. Within the training set, the labeled and unlabeled data are also split by patient to maintain patient-level separation. We adopt a default labeled-to-unlabeled data ratio of 2:8, meaning that 20% of the training samples are labeled while the remaining 80% are treated as unlabeled. The split is also performed at the patient level, ensuring that all images from a single patient are assigned exclusively to either the labeled or the unlabeled subset.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28756</offset><text>Implementation Details. The proposed framework is implemented in PyTorch 2.5.0, and all experiments are performed on one NVIDIA GeForce RTX 4090 GPU and an Intel(R) Xeon(R) Silver 4214R CPU @ 2.40GHz. The network backbone is ViT-B/16-224. For experiments on the in-house collected Daping dataset, the visual encoder is initialized through self-supervised pretraining on the training set using i-JEPA. For experiments on the publicly available LIMUC dataset, we initialize the visual encoder directly with ImageNet-pretrained weights to facilitate reproducibility. It is worth noting that for fair comparison, all competing methods evaluated on the same dataset employ the identical visual encoder with the same initialization strategy. The weak augmentation  includes random cropping and flipping. We adopt RandAugment as the strong augmentation function . The training batch sizes for labeled and unlabeled data are 40 and 80, respectively. For the hyperparameters, we empirically set , , , , , , , and . The AdamW optimizer is employed with a weight decay of . The learning rate is initialized to  and linearly decreases to  over 150 epochs. The model saved at the end of 150 epochs is used for testing.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29962</offset><text>Evaluation Metrics. We report the classification performance using four evaluation metrics: accuracy, specificity, sensitivity and F1-score. Accuracy is calculated as the proportion of correctly classified samples over the entire test set. In addition, sensitivity, specificity, and F1-score are computed for each class and then averaged across all classes. Specifically, for each class c, , , , and  denote the true positives, true negatives, false positives, and false negatives, respectively. Then, the evaluation metrics are calculated by</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>30505</offset><text>4.2. Comparison with State-of-the-Art Semi-Supervised Learning Methods</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30576</offset><text>To evaluate performance, we compared our method with five SOTA semi-supervised learning methods on both the Daping dataset and the LIMUC dataset. The characteristics of each SOTA method are summarized as follows. (1) FixMatch, which combines pseudo-labeling with consistency regularization, and applies a fixed confidence threshold to ensure the quality of pseudo-labels; (2) FreeMatch, which extends FixMatch by adopting an adaptive thresholding strategy that dynamically adjusts the confidence threshold in a class-aware manner, achieving a better quality–quantity trade-off; (3) Class-aware Semi-supervised Contrastive Learning (CCSSL), which integrates a class-aware contrastive module into the FixMatch framework. It separately handles in-distribution data with class-level clustering and out-of-distribution data with instance-level contrastive; (4) SoftMatch, which extends FixMatch by using a truncated Gaussian weighting function to assign confidence-based weights to unlabeled samples rather than using a fixed threshold to filter them; (5) Semantic-aware FixMatch (SA-FixMatch), which replaces the standard random CutOut in FixMatch’s strong augmentation with a semantic-aware CutOut.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31776</offset><text>Moreover, to quantify the performance of different competing methods, we trained two additional models on the dataset. These two models had the same network architecture as our method. The first model, referred to as the upper bound, was trained on 100% labeled data in a fully supervised manner, while the second model, referred to as the baseline, was trained in a fully supervised manner on 20% labeled data without using any unlabeled data.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32221</offset><text>To assess the statistical significance of performance differences between models, we apply bootstrap resampling to estimate the distribution of pairwise differences in F1-score, as the F1-score provides a more reliable overall metric than accuracy for imbalanced classification. A 95% confidence interval (CI) of the difference is then computed. Following established statistical interpretation, when a confidence interval (CI) includes zero, it means that the observed difference is not statistically significant at the 95% confidence level.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32764</offset><text>Results on the Daping Dataset. The quantitative comparison with the competing SOTA methods when using 20% labeled data for training is presented in Table 2. From this table, one can observe that our method achieves the best classification performance with an accuracy of , a sensitivity of  and an F1-score of . Specifically, our method outperforms the second-best method (CCSSL) by a margin of ,  and  in terms of accuracy, sensitivity and F1-score, respectively. Moreover, the 95% CI of the F1-score difference is [0.003, 0.041], which does not include zero, indicating that the performance improvement of our method over CCSSL is statistically significant at the 95% confidence level for the semi-supervised IBD classification task. The experimental results demonstrate the effectiveness of the proposed method in the semi-supervised IBD classification of colonoscopy images. Additionally, from Table 2, one can observe that our proposed SACSSL surpasses the baseline performance by a substantial margin of , ,  and  in terms of accuracy, sensitivity, specificity and F1-score, respectively, and it is close to the upper-bound performance, with a small gap of , ,  and  in terms of accuracy, sensitivity, specificity and F1-score, respectively. These results demonstrate the superior capability of our method in leveraging the unlabeled data for the semi-supervised IBD classification of colonoscopy images.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>34175</offset><text>Results on the LIMUC Dataset. The quantitative comparison with the competing SOTA methods when using 20% labeled data for training is presented in Table 3. From this table, one can observe that our method achieves the highest accuracy (76.4%) and F1-score (68.9%) along with a sensitivity of 67.7% and a specificity of 91.0%. In comparison, CCSSL attains a higher sensitivity of 68.9% and a specificity of 91.2% but with lower accuracy (75.9%) and F1-score (68.0%). The 95% CI of the F1-score difference between our method and CCSSL is [−0.005, 0.026], indicating that the performance improvement is not statistically significant at the 95% confidence level. This outcome may be attributed to the inherent characteristics of the UC severity grading task, which consists of fine-grained categories with smaller inter-class differences and more constrained intra-class variation, naturally limiting the potential gains achievable by the subclass-aware contrastive module. Despite these constraints, our method still achieves the highest overall accuracy and F1-score. The experimental results demonstrate the effectiveness of the proposed method in semi-supervised UC severity grading, indicating its adaptability across different IBD-related colonoscopy image classification tasks.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>35458</offset><text>4.3. Analytical Ablation Studies</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>35491</offset><text>We further conduct analytical ablation studies on the Daping dataset to investigate the effectiveness of different components of the proposed method. In particular, we conduct the following analytical ablation studies: (1) We first evaluate the classification performance of the proposed method using different percentages of labeled data; (2) We then investigate the effectiveness of each loss to the overall classification performance gain in the proposed method; (3) We further investigate the influence of the confidence threshold  and the number of prototypes per class K in the subclass-aware contrastive module on the performance of the proposed method; (4) Additionally, we investigate the influence of the visual encoder backbone on the performance of the proposed method; (5) Finally, we conduct an analysis of learned features.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>36330</offset><text>Evaluation under Different Percentages of Labeled Data. We conducted an ablation study to investigate the impact of the percentage of labeled data on the performance of the proposed method. We compared our method with the baseline model when 5%, 10%, 20% and 30% labeled data were used for training. In particular, the baseline model was trained in a supervised manner using only the labeled data, while our method was trained in a semi-supervised manner using both labeled and unlabeled data. The experimental results are presented in Table 4. As shown in this table, our method demonstrates consistent classification performance improvement under all proportions of labeled data compared to the baseline performance. Notably, when trained with only 5% labeled data, our method outperforms the baseline performance by a large margin of , , and  in terms of accuracy, specificity and F1-score, respectively, demonstrating its effectiveness in leveraging unlabeled data under very limited labeled data. As the proportion of labeled data increases to 30%, our method outperforms the baseline performance by a margin of , , , and  in terms of accuracy, sensitivity, specificity, and F1-score, respectively. These results demonstrate the superior capability of our method in leveraging the unlabeled data to improve classification performance.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>37670</offset><text>Effectiveness of Different Losses. To validate the effectiveness of different losses used in our method, we conduct an ablation study by training the model with different combinations of losses using 20% labeled data: (1) ; (2) ; (3) ; (4) ; and (5)  (where  is a combination of  and ). The experimental results are reported in Table 5. Compared to the baseline model trained with  alone, the model trained with  and  improves the classification performance by a margin of 1.0% in terms of accuracy, while showing a performance drop by a margin of 3.1% and 1.1% in terms of sensitivity and F1-score, respectively, which could be potentially attributed to confirmation bias. In addition to  and , incorporating  further improves the accuracy, sensitivity, specificity and F1-score by a margin of 0.4%, 4.2%, 0.8% and 2.9%, respectively, which demonstrates the effectiveness of the instance-level contrastive loss when applied to uncertain samples. Similarly, incorporating  in addition to  and  improves the classification performance by a margin of 0.5%, 2.0%, 0.5% and 1.5% in terms of accuracy, sensitivity, specificity and F1-score, respectively, demonstrating the effectiveness of the subclass-level contrastive loss when applied to confident samples. Finally, the model that incorporates all the losses results in the best classification performance, outperforming the second-best classification performance by a margin of 0.7%, 1.5%, 0.2%, and 2.8% in terms of accuracy, sensitivity, specificity, and F1-score, respectively, which demonstrates the two complementary components of our subclass-aware contrastive loss , composed of  and , provide synergistic benefits for representation learning. These results demonstrate that the subclass-aware contrastive loss, derived from our proposed subclass-aware contrastive module, effectively enhances representation learning and improves the overall classification performance.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>39598</offset><text>Influence of the Confidence Threshold . The confidence threshold  determines the separation of confident and uncertain samples in our method. A low  may include samples with incorrect pseudo-labels in the confident set, introducing noise to subclass-level contrastive learning, whereas a high  may exclude correctly pseudo-labeled samples from the confident set, which weakens the effectiveness of subclass-level contrastive learning. To investigate the influence of the confidence threshold, we conduct an ablation study by setting  to a value in . The experimental results are reported in Table 6. From this table, one can observe that the model achieves the best classification performance when  is set to 0.9 with an accuracy of 93.2% and an F1-score of 80.1%. Therefore, we adopt  in our study.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>40398</offset><text>Influence of the Number of Prototypes per Class . The number of prototypes per class K controls the subclass granularity within each multi-view batch. Too few prototypes may fail to capture fine-grained intra-class variations in IBD colonoscopy images, while too many prototypes may push semantically similar samples away in the embedding space, reducing the effectiveness of contrastive learning. Here, we conduct an ablation study to investigate the performance of the proposed method when setting different K values, where K is in . The experimental results are reported in Table 7. From this table, the model achieves the best classification performance when K is set to 3 with an accuracy of 93.2% and an F1-score of 80.1%. Therefore, we adopt  in our study.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>41162</offset><text>Influence of the Visual Encoder Backbone. The choice of visual encoder backbone directly affects the quality of extracted visual features, which in turn influences classification performance. To evaluate this effect, we conduct an ablation study using three widely adopted models as the visual encoder backbone: two CNN-based models, ResNet50 and EfficientNet-B5, and a transformer-based model, ViT-B. The experimental results are summarized in Table 8. From this table, one can observe that when using ViT-B as the visual encoder, our method achieves the best classification performance, outperforming the best CNN-based backbone (ResNet-50) by a margin of 1.7%, 0.1%, 1.1%, and 2.5% in terms of accuracy, sensitivity, specificity, and F1-score, respectively. These results indicate that the transformer-based backbone consistently outperforms the CNN-based backbones in the semi-supervised colonoscopy image classification task. Accordingly, we adopt ViT-B as the visual encoder backbone in our study.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>42166</offset><text>Analysis of the Learned Features. To validate the effectiveness of our method in representation learning, we use the t-SNE algorithm to visualize the distributions of learned features extracted from the visual encoder  by projecting the embedded features into a two-dimensional space. In Figure 3, we present a qualitative comparison of the t-SNE visualization on the Daping test set between FixMatch and the proposed SACSSL. The t-SNE analysis is implemented in Python using the scikit-learn package (version 1.5.1). Each point in Figure 3 represents the embedded feature from one colonoscopy image and is color-coded using the ground truth class label. From this figure, one can see that the classification boundary learned by FixMatch, especially between UC and CD, is unclear, such that it is difficult to correctly classify IBD from colonoscopy images. By incorporating our proposed subclass-aware contrastive module, SACSSL learns feature representations with clearer inter-class boundaries, while intra-class features are further partitioned into multiple compact clusters according to their semantic information. This explains why the proposed SACSSL achieves superior classification performance.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>43371</offset><text>5. Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43385</offset><text>The accurate classification of IBD from colonoscopy images is critical for timely diagnosis and effective treatment. Although deep learning-based approaches have achieved impressive performance in various medical image classification tasks, developing robust models for IBD diagnosis remains challenging due to the limited availability of annotated endoscopic data and the severe intra-class heterogeneity of colonoscopy images. Semi-supervised learning methods provide a promising alternative to this problem by leveraging both labeled and unlabeled data. In particular, the pseudo-labeling-based framework combined with consistency regularization has proven to be an effective and simple approach. CCSSL extended pseudo-labeling-based frameworks by refining learned features through class-aware contrastive learning that promotes intra-class clustering. Although this approach performs well on natural image tasks, it struggles to capture the substantial intra-class heterogeneity of colonoscopy images in IBD classification. However, prior approaches for modeling intra-class heterogeneity either rely on fully supervised subclass decomposition that cannot exploit unlabeled data or adopt class-agnostic prototype learning in a self-supervised manner, making it difficult to simultaneously leverage unlabeled data and capture fine-grained intra-class variations for IBD classification. To address these limitations, we propose SACSSL, which incorporates the proposed subclass-aware contrastive module into the FixMatch framework. This design enables us to refine learned features by applying an instance-level contrastive loss to distinguish uncertain samples and applying a subclass-level contrastive loss to confident samples to learn hierarchical clustered representations within each class. We evaluate our method on an in-house collected colonoscopy image dataset for IBD classification, which is referred to as the Daping dataset. The proposed method outperforms the SOTA methods, as presented in Table 2. As demonstrated in Table 4, our method achieves consistently improved performance compared to the baseline performance regardless of the percentage of labeled data, which demonstrates that our model can effectively leverage unlabeled data. Moreover, we further evaluate our method on the publicly available LIMUC dataset for UC severity grading, which is an IBD-related classification task. As shown in Table 3, our method outperforms other competing SOTA methods, demonstrating its effectiveness on UC severity grading as an additional colonoscopy image classification task.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>45976</offset><text>The key to the superior performance of SACSSL lies in the carefully designed subclass-aware contrastive module. In particular, we leverage subclass prototypes to partition confident samples into subclasses and apply supervised contrastive loss to learn hierarchical, clustered representations within each class. Quantitative and qualitative results from our analytical ablation studies conducted on the Daping dataset demonstrate that SACSSL learns better-separated feature representations with the proposed subclass-aware contrastive module, as demonstrated by Figure 3 and Table 5.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>46560</offset><text>The clinical implications of the proposed method merit further discussion. In clinical practice, large amounts of colonoscopy data are readily available, whereas obtaining expert annotations remains costly and time consuming. By effectively leveraging abundant unlabeled data available in clinical archives, the proposed framework alleviates the heavy reliance on expert annotations, which is one of the major barriers to the real-world deployment of deep learning models. Moreover, the improved inter-class separability and preserved intra-class diversity achieved through subclass-aware contrastive learning enhance the model’s capability to distinguish between UC and CD, which is a clinically important yet challenging task even for experienced endoscopists. Collectively, these advantages highlight the potential clinical impact of the proposed method in supporting large-scale, annotation-efficient colonoscopy image diagnosis.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>47496</offset><text>In addition, several limitations of the current study, as well as potential directions for future research, deserve further discussion. First, although the proposed method achieves consistently superior performance on both the in-house Daping dataset and the publicly available LIMUC dataset, the current evaluation is still limited to single-center data. However, differences in patient populations, imaging devices, and acquisition protocols across institutions may introduce domain shifts, which could potentially lead to degraded performance on external datasets. Recent studies have shown that semi-supervised domain adaptation techniques can effectively mitigate such discrepancies by leveraging labeled source data and unlabeled target domain data, which provides a promising direction for extending the proposed framework to multi-center scenarios. Second, the present work follows a closed-set semi-supervised learning setting, where all categories in the unlabeled data are assumed to be known. However, in real-world clinical environments, unlabeled data may inevitably contain unknown categories. Recent advances in open-set and universal semi-supervised learning offer potential solutions by explicitly handling unknown samples during training. In future studies, integrating such strategies into the proposed framework could further enhance its robustness in practical scenarios. Third, the hyperparameters in this study were selected empirically. Although the current configuration already yields superior performance compared to other competing SOTA methods, more systematic hyperparameter optimization strategies, such as grid search, could be explored in future work to potentially achieve further performance gains.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>49231</offset><text>6. Conclusions</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>49246</offset><text>In this paper, we propose a novel subclass-aware contrastive semi-supervised learning framework for accurate colonoscopy image classification, which is referred to as SACSSL. The proposed framework features a novel subclass-aware contrastive module, which explicitly captures intra-class heterogeneity by adaptively applying instance-level contrastive learning to uncertain samples and prototype-based subclass-level contrastive learning to confident samples, thereby enhancing inter-class separability while preserving fine-grained intra-class diversity and mitigating confirmation bias. Comprehensive experiments on both the in-house Daping dataset and the public LIMUC dataset demonstrate that SACSSL consistently outperforms existing semi-supervised learning methods in both IBD classification and UC severity grading. In addition, the t-SNE analysis further confirms that SACSSL is capable of learning clear classification boundaries while preserving fine-grained intra-class semantics, highlighting its effectiveness in IBD classification from colonoscopy images. In future work, we will focus on extending the proposed framework to semi-supervised domain adaptation, aiming to improve robustness across centers with different endoscopy systems and patient populations. Moreover, we will explore the universal semi-supervised learning method to explicitly handle non-IBD or atypical colonoscopic findings that commonly appear in large-scale unlabeled clinical data.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">footnote</infon><offset>50718</offset><text>Disclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>51090</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>51111</offset><text>Conceptualization, K.L., X.Z., Y.N., Y.W. and G.Z.; Methodology, K.L., G.R., X.Z., Y.W. and G.Z.; Software, K.L.; Validation, K.L., G.R. and X.Z.; Formal analysis, K.L.; Investigation, K.L., G.R., X.Z., Y.N. and G.Z.; Resources, Y.W. and G.Z.; Data curation, K.L., G.R., X.Z. and Y.N.; Writing—original draft, K.L.; Writing—review &amp; editing, G.R., X.Z., Y.N., Y.W. and G.Z.; Visualization, K.L.; Supervision, Y.N., Y.W. and G.Z.; Project administration, Y.N., Y.W. and G.Z.; Funding acquisition, Y.N., Y.W. and G.Z. All authors have read and agreed to the published version of the manuscript.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title</infon><offset>51708</offset><text>Data Availability Statement</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>51736</offset><text>The original contributions presented in this study are included in the article. Further inquiries can be directed to the corresponding author.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>51879</offset><text>Conflicts of Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>51901</offset><text>The authors declare no conflict of interest.</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">title</infon><offset>51946</offset><text>Abbreviations</text></passage><passage><infon key="file">no_id_0.xml</infon><infon key="id">no_id_0</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;IBD&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Inflammatory bowel disease&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CD&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Crohn’s disease&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;UC&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ulcerative colitis&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;WCE&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wireless capsule endoscopy&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;PCE&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Panenteric capsule endoscopy&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MES&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mayo Endoscopic Score&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CI&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Confidence interval&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;
</infon><offset>51960</offset><text>IBD	Inflammatory bowel disease	 	CD	Crohn’s disease	 	UC	Ulcerative colitis	 	WCE	Wireless capsule endoscopy	 	PCE	Panenteric capsule endoscopy	 	MES	Mayo Endoscopic Score	 	CI	Confidence interval	 	</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>52162</offset><text>The following abbreviations are used in this manuscript: </text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>52220</offset><text>References</text></passage><passage><infon key="fpage">1627</infon><infon key="lpage">1640</infon><infon key="name_0">surname:Baumgart;given-names:D.C.</infon><infon key="name_1">surname:Carding;given-names:S.R.</infon><infon key="pub-id_doi">10.1016/S0140-6736(07)60750-8</infon><infon key="pub-id_pmid">17499605</infon><infon key="section_type">REF</infon><infon key="source">Lancet</infon><infon key="type">ref</infon><infon key="volume">369</infon><infon key="year">2007</infon><offset>52231</offset><text>Inflammatory bowel disease: Cause and immunobiology</text></passage><passage><infon key="fpage">2769</infon><infon key="lpage">2778</infon><infon key="name_0">surname:Ng;given-names:S.C.</infon><infon key="name_1">surname:Shi;given-names:H.Y.</infon><infon key="name_2">surname:Hamidi;given-names:N.</infon><infon key="name_3">surname:Underwood;given-names:F.E.</infon><infon key="name_4">surname:Tang;given-names:W.</infon><infon key="name_5">surname:Benchimol;given-names:E.I.</infon><infon key="name_6">surname:Panaccione;given-names:R.</infon><infon key="name_7">surname:Ghosh;given-names:S.</infon><infon key="name_8">surname:Wu;given-names:J.C.</infon><infon key="name_9">surname:Chan;given-names:F.K.</infon><infon key="pub-id_doi">10.1016/S0140-6736(17)32448-0</infon><infon key="pub-id_pmid">29050646</infon><infon key="section_type">REF</infon><infon key="source">Lancet</infon><infon key="type">ref</infon><infon key="volume">390</infon><infon key="year">2017</infon><offset>52283</offset><text>Worldwide incidence and prevalence of inflammatory bowel disease in the 21st century: A systematic review of population-based studies</text></passage><passage><infon key="fpage">458</infon><infon key="lpage">466</infon><infon key="name_0">surname:Hracs;given-names:L.</infon><infon key="name_1">surname:Windsor;given-names:J.W.</infon><infon key="name_2">surname:Gorospe;given-names:J.</infon><infon key="name_3">surname:Cummings;given-names:M.</infon><infon key="name_4">surname:Coward;given-names:S.</infon><infon key="name_5">surname:Buie;given-names:M.J.</infon><infon key="name_6">surname:Quan;given-names:J.</infon><infon key="name_7">surname:Goddard;given-names:Q.</infon><infon key="name_8">surname:Caplan;given-names:L.</infon><infon key="name_9">surname:Markovinović;given-names:A.</infon><infon key="pub-id_doi">10.1038/s41586-025-08940-0</infon><infon key="pub-id_pmid">40307548</infon><infon key="section_type">REF</infon><infon key="source">Nature</infon><infon key="type">ref</infon><infon key="volume">642</infon><infon key="year">2025</infon><offset>52417</offset><text>Global evolution of inflammatory bowel disease across epidemiologic stages</text></passage><passage><infon key="fpage">769</infon><infon key="lpage">784</infon><infon key="name_0">surname:Harbord;given-names:M.</infon><infon key="name_1">surname:Eliakim;given-names:R.</infon><infon key="name_2">surname:Bettenworth;given-names:D.</infon><infon key="name_3">surname:Karmiris;given-names:K.</infon><infon key="name_4">surname:Katsanos;given-names:K.</infon><infon key="name_5">surname:Kopylov;given-names:U.</infon><infon key="name_6">surname:Kucharzik;given-names:T.</infon><infon key="name_7">surname:Molnár;given-names:T.</infon><infon key="name_8">surname:Raine;given-names:T.</infon><infon key="name_9">surname:Sebastian;given-names:S.</infon><infon key="pub-id_doi">10.1093/ecco-jcc/jjx009</infon><infon key="pub-id_pmid">28513805</infon><infon key="section_type">REF</infon><infon key="source">J. Crohn’s Colitis</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2017</infon><offset>52492</offset><text>Third European evidence-based consensus on diagnosis and management of ulcerative colitis. Part 2: Current management</text></passage><passage><infon key="fpage">s1</infon><infon key="lpage">s101</infon><infon key="name_0">surname:Moran;given-names:G.W.</infon><infon key="name_1">surname:Gordon;given-names:M.</infon><infon key="name_2">surname:Sinopolou;given-names:V.</infon><infon key="name_3">surname:Radford;given-names:S.J.</infon><infon key="name_4">surname:Darie;given-names:A.M.</infon><infon key="name_5">surname:Vuyyuru;given-names:S.K.</infon><infon key="name_6">surname:Alrubaiy;given-names:L.</infon><infon key="name_7">surname:Arebi;given-names:N.</infon><infon key="name_8">surname:Blackwell;given-names:J.</infon><infon key="name_9">surname:Butler;given-names:T.D.</infon><infon key="pub-id_doi">10.1136/gutjnl-2024-334395</infon><infon key="pub-id_pmid">40550582</infon><infon key="section_type">REF</infon><infon key="source">Gut</infon><infon key="type">ref</infon><infon key="volume">74</infon><infon key="year">2025</infon><offset>52610</offset><text>British Society of Gastroenterology guidelines on inflammatory bowel disease in adults: 2025</text></passage><passage><infon key="fpage">305</infon><infon key="lpage">314</infon><infon key="name_0">surname:Miehlke;given-names:S.</infon><infon key="name_1">surname:Verhaegh;given-names:B.</infon><infon key="name_2">surname:Tontini;given-names:G.E.</infon><infon key="name_3">surname:Madisch;given-names:A.</infon><infon key="name_4">surname:Langner;given-names:C.</infon><infon key="name_5">surname:Münch;given-names:A.</infon><infon key="pub-id_doi">10.1016/S2468-1253(19)30048-2</infon><infon key="pub-id_pmid">30860066</infon><infon key="section_type">REF</infon><infon key="source">Lancet Gastroenterol. Hepatol.</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2019</infon><offset>52703</offset><text>Microscopic colitis: Pathophysiology and clinical management</text></passage><passage><infon key="fpage">254</infon><infon key="lpage">262</infon><infon key="name_0">surname:Jung;given-names:S.A.</infon><infon key="pub-id_doi">10.5946/ce.2012.45.3.254</infon><infon key="pub-id_pmid">22977813</infon><infon key="section_type">REF</infon><infon key="source">Clin. Endosc.</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">2012</infon><offset>52764</offset><text>Differential diagnosis of inflammatory bowel disease: What is the role of colonoscopy?</text></passage><passage><infon key="fpage">4014</infon><infon key="name_0">surname:Spiceland;given-names:C.M.</infon><infon key="name_1">surname:Lodhia;given-names:N.</infon><infon key="pub-id_doi">10.3748/wjg.v24.i35.4014</infon><infon key="pub-id_pmid">30254405</infon><infon key="section_type">REF</infon><infon key="source">World J. Gastroenterol.</infon><infon key="type">ref</infon><infon key="volume">24</infon><infon key="year">2018</infon><offset>52851</offset><text>Endoscopy in inflammatory bowel disease: Role in diagnosis, management, and treatment</text></passage><passage><infon key="fpage">106</infon><infon key="lpage">111</infon><infon key="name_0">surname:Shichijo;given-names:S.</infon><infon key="name_1">surname:Nomura;given-names:S.</infon><infon key="name_2">surname:Aoyama;given-names:K.</infon><infon key="name_3">surname:Nishikawa;given-names:Y.</infon><infon key="name_4">surname:Miura;given-names:M.</infon><infon key="name_5">surname:Shinagawa;given-names:T.</infon><infon key="name_6">surname:Takiyama;given-names:H.</infon><infon key="name_7">surname:Tanimoto;given-names:T.</infon><infon key="name_8">surname:Ishihara;given-names:S.</infon><infon key="name_9">surname:Matsuo;given-names:K.</infon><infon key="pub-id_doi">10.1016/j.ebiom.2017.10.014</infon><infon key="pub-id_pmid">29056541</infon><infon key="section_type">REF</infon><infon key="source">EBioMedicine</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2017</infon><offset>52937</offset><text>Application of convolutional neural networks in the diagnosis of Helicobacter pylori infection based on endoscopic images</text></passage><passage><infon key="fpage">356</infon><infon key="lpage">369</infon><infon key="name_0">surname:Karadag;given-names:P.</infon><infon key="name_1">surname:Morris;given-names:B.</infon><infon key="name_2">surname:Woolfall;given-names:K.</infon><infon key="pub-id_doi">10.1177/1742395320968617</infon><infon key="pub-id_pmid">33106026</infon><infon key="section_type">REF</infon><infon key="source">Chronic Illn.</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2022</infon><offset>53059</offset><text>The information and support needs of patients living with inflammatory bowel disease: A qualitative study</text></passage><passage><infon key="fpage">3228832</infon><infon key="name_0">surname:Chang;given-names:Y.</infon><infon key="name_1">surname:Wang;given-names:Z.</infon><infon key="name_2">surname:Sun;given-names:H.B.</infon><infon key="name_3">surname:Li;given-names:Y.Q.</infon><infon key="name_4">surname:Tang;given-names:T.Y.</infon><infon key="pub-id_doi">10.1155/2023/3228832</infon><infon key="pub-id_pmid">37101782</infon><infon key="section_type">REF</infon><infon key="source">Gastroenterol. Res. Pract.</infon><infon key="type">ref</infon><infon key="volume">2023</infon><infon key="year">2023</infon><offset>53165</offset><text>Artificial intelligence in inflammatory bowel disease endoscopy: Advanced development and new horizons</text></passage><passage><infon key="elocation-id">854677</infon><infon key="name_0">surname:Ruan;given-names:G.</infon><infon key="name_1">surname:Qi;given-names:J.</infon><infon key="name_2">surname:Cheng;given-names:Y.</infon><infon key="name_3">surname:Liu;given-names:R.</infon><infon key="name_4">surname:Zhang;given-names:B.</infon><infon key="name_5">surname:Zhi;given-names:M.</infon><infon key="name_6">surname:Chen;given-names:J.</infon><infon key="name_7">surname:Xiao;given-names:F.</infon><infon key="name_8">surname:Shen;given-names:X.</infon><infon key="name_9">surname:Fan;given-names:L.</infon><infon key="pub-id_doi">10.3389/fmed.2022.854677</infon><infon key="section_type">REF</infon><infon key="source">Front. Med.</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2022</infon><offset>53268</offset><text>Development and validation of a deep neural network for accurate identification of endoscopic images from patients with ulcerative colitis and Crohn’s disease</text></passage><passage><infon key="elocation-id">1531362</infon><infon key="name_0">surname:Bin;given-names:Y.</infon><infon key="name_1">surname:Peng;given-names:R.</infon><infon key="name_2">surname:Lee;given-names:Y.</infon><infon key="name_3">surname:Lee;given-names:Z.</infon><infon key="name_4">surname:Liu;given-names:Y.</infon><infon key="pub-id_doi">10.3389/frai.2025.1531362</infon><infon key="pub-id_pmid">40235858</infon><infon key="section_type">REF</infon><infon key="source">Front. Artif. Intell.</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2025</infon><offset>53429</offset><text>Artificial intelligence-assisted capsule endoscopy for detecting lesions in Crohn’s disease: A systematic review and meta-analysis</text></passage><passage><infon key="fpage">373</infon><infon key="lpage">440</infon><infon key="name_0">surname:Van Engelen;given-names:J.E.</infon><infon key="name_1">surname:Hoos;given-names:H.H.</infon><infon key="pub-id_doi">10.1007/s10994-019-05855-6</infon><infon key="section_type">REF</infon><infon key="source">Mach. Learn.</infon><infon key="type">ref</infon><infon key="volume">109</infon><infon key="year">2020</infon><offset>53562</offset><text>A survey on semi-supervised learning</text></passage><passage><infon key="elocation-id">198345</infon><infon key="name_0">surname:Guo;given-names:L.Z.</infon><infon key="name_1">surname:Jia;given-names:L.H.</infon><infon key="name_2">surname:Shao;given-names:J.J.</infon><infon key="name_3">surname:Li;given-names:Y.F.</infon><infon key="pub-id_doi">10.1007/s11704-024-40646-w</infon><infon key="section_type">REF</infon><infon key="source">Front. Comput. Sci.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2025</infon><offset>53599</offset><text>Robust semi-supervised learning in open environments</text></passage><passage><infon key="fpage">896</infon><infon key="name_0">surname:Lee;given-names:D.H.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Workshop on Challenges in Representation Learning, ICML</infon><infon key="type">ref</infon><infon key="volume">Volume 3</infon><offset>53652</offset><text>Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">9</infon><infon key="name_0">surname:Sajjadi;given-names:M.</infon><infon key="name_1">surname:Javanmardi;given-names:M.</infon><infon key="name_2">surname:Tasdizen;given-names:T.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2016</infon><offset>53748</offset><text>Regularization with stochastic transformations and perturbations for deep semi-supervised learning</text></passage><passage><infon key="fpage">596</infon><infon key="lpage">608</infon><infon key="name_0">surname:Sohn;given-names:K.</infon><infon key="name_1">surname:Berthelot;given-names:D.</infon><infon key="name_2">surname:Carlini;given-names:N.</infon><infon key="name_3">surname:Zhang;given-names:Z.</infon><infon key="name_4">surname:Zhang;given-names:H.</infon><infon key="name_5">surname:Raffel;given-names:C.A.</infon><infon key="name_6">surname:Cubuk;given-names:E.D.</infon><infon key="name_7">surname:Kurakin;given-names:A.</infon><infon key="name_8">surname:Li;given-names:C.L.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2020</infon><offset>53847</offset><text>Fixmatch: Simplifying semi-supervised learning with consistency and confidence</text></passage><passage><infon key="fpage">5033612</infon><infon key="name_0">surname:Weng;given-names:W.</infon><infon key="name_1">surname:Zhu;given-names:X.</infon><infon key="name_2">surname:Cheikh;given-names:F.A.</infon><infon key="name_3">surname:Ullah;given-names:M.</infon><infon key="name_4">surname:Imaizumi;given-names:M.</infon><infon key="name_5">surname:Murono;given-names:S.</infon><infon key="name_6">surname:Kubota;given-names:S.</infon><infon key="pub-id_doi">10.1109/TIM.2024.3470015</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Instrum. Meas.</infon><infon key="type">ref</infon><infon key="volume">73</infon><infon key="year">2024</infon><offset>53926</offset><text>A simple framework for depth-augmented contrastive learning for endoscopic image classification</text></passage><passage><infon key="fpage">107280</infon><infon key="name_0">surname:Huang;given-names:Z.</infon><infon key="name_1">surname:Wu;given-names:J.</infon><infon key="name_2">surname:Wang;given-names:T.</infon><infon key="name_3">surname:Li;given-names:Z.</infon><infon key="name_4">surname:Ioannou;given-names:A.</infon><infon key="pub-id_doi">10.1016/j.compbiomed.2023.107280</infon><infon key="pub-id_pmid">37517324</infon><infon key="section_type">REF</infon><infon key="source">Comput. Biol. Med.</infon><infon key="type">ref</infon><infon key="volume">164</infon><infon key="year">2023</infon><offset>54022</offset><text>Class-specific distribution alignment for semi-supervised medical image classification</text></passage><passage><infon key="fpage">4968</infon><infon key="lpage">4976</infon><infon key="name_0">surname:Li;given-names:W.</infon><infon key="name_1">surname:Ju;given-names:L.</infon><infon key="name_2">surname:Tang;given-names:F.</infon><infon key="name_3">surname:Xia;given-names:P.</infon><infon key="name_4">surname:Xiong;given-names:X.</infon><infon key="name_5">surname:Hu;given-names:M.</infon><infon key="name_6">surname:Zhu;given-names:L.</infon><infon key="name_7">surname:Ge;given-names:Z.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the AAAI Conference on Artificial Intelligence</infon><infon key="type">ref</infon><infon key="volume">Volume 39</infon><offset>54109</offset><text>Towards Realistic Semi-supervised Medical Image Classification</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">8</infon><infon key="name_0">surname:Arazo;given-names:E.</infon><infon key="name_1">surname:Ortego;given-names:D.</infon><infon key="name_2">surname:Albert;given-names:P.</infon><infon key="name_3">surname:O’Connor;given-names:N.E.</infon><infon key="name_4">surname:McGuinness;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)</infon><infon key="type">ref</infon><offset>54172</offset><text>Pseudo-labeling and confirmation bias in deep semi-supervised learning</text></passage><passage><infon key="fpage">1597</infon><infon key="lpage">1607</infon><infon key="name_0">surname:Chen;given-names:T.</infon><infon key="name_1">surname:Kornblith;given-names:S.</infon><infon key="name_2">surname:Norouzi;given-names:M.</infon><infon key="name_3">surname:Hinton;given-names:G.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Machine Learning</infon><infon key="type">ref</infon><offset>54243</offset><text>A simple framework for contrastive learning of visual representations</text></passage><passage><infon key="fpage">9729</infon><infon key="lpage">9738</infon><infon key="name_0">surname:He;given-names:K.</infon><infon key="name_1">surname:Fan;given-names:H.</infon><infon key="name_2">surname:Wu;given-names:Y.</infon><infon key="name_3">surname:Xie;given-names:S.</infon><infon key="name_4">surname:Girshick;given-names:R.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>54313</offset><text>Momentum contrast for unsupervised visual representation learning</text></passage><passage><infon key="fpage">14421</infon><infon key="lpage">14430</infon><infon key="name_0">surname:Yang;given-names:F.</infon><infon key="name_1">surname:Wu;given-names:K.</infon><infon key="name_2">surname:Zhang;given-names:S.</infon><infon key="name_3">surname:Jiang;given-names:G.</infon><infon key="name_4">surname:Liu;given-names:Y.</infon><infon key="name_5">surname:Zheng;given-names:F.</infon><infon key="name_6">surname:Zhang;given-names:W.</infon><infon key="name_7">surname:Wang;given-names:C.</infon><infon key="name_8">surname:Zeng;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>54379</offset><text>Class-aware contrastive semi-supervised learning</text></passage><passage><infon key="fpage">19339</infon><infon key="lpage">19352</infon><infon key="name_0">surname:Sohoni;given-names:N.</infon><infon key="name_1">surname:Dunnmon;given-names:J.</infon><infon key="name_2">surname:Angus;given-names:G.</infon><infon key="name_3">surname:Gu;given-names:A.</infon><infon key="name_4">surname:Ré;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2020</infon><offset>54428</offset><text>No subclass left behind: Fine-grained robustness in coarse-grained classification problems</text></passage><passage><infon key="fpage">16275</infon><infon key="lpage">16294</infon><infon key="name_0">surname:Grcic;given-names:M.</infon><infon key="name_1">surname:Gadetsky;given-names:A.</infon><infon key="name_2">surname:Brbic;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Machine Learning</infon><infon key="type">ref</infon><offset>54519</offset><text>Fine-Grained Classes and How to Find Them</text></passage><passage><infon key="fpage">9912</infon><infon key="lpage">9924</infon><infon key="name_0">surname:Caron;given-names:M.</infon><infon key="name_1">surname:Misra;given-names:I.</infon><infon key="name_2">surname:Mairal;given-names:J.</infon><infon key="name_3">surname:Goyal;given-names:P.</infon><infon key="name_4">surname:Bojanowski;given-names:P.</infon><infon key="name_5">surname:Joulin;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2020</infon><offset>54561</offset><text>Unsupervised learning of visual features by contrasting cluster assignments</text></passage><passage><infon key="fpage">132</infon><infon key="lpage">149</infon><infon key="name_0">surname:Caron;given-names:M.</infon><infon key="name_1">surname:Bojanowski;given-names:P.</infon><infon key="name_2">surname:Joulin;given-names:A.</infon><infon key="name_3">surname:Douze;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the European Conference on Computer Vision (ECCV)</infon><infon key="type">ref</infon><offset>54637</offset><text>Deep clustering for unsupervised learning of visual features</text></passage><passage><infon key="fpage">281</infon><infon key="lpage">297</infon><infon key="name_0">surname:McQueen;given-names:J.B.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability</infon><infon key="type">ref</infon><offset>54698</offset><text>Some methods of classification and analysis of multivariate observations</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">9</infon><infon key="name_0">surname:Cuturi;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">26</infon><infon key="year">2013</infon><offset>54771</offset><text>Sinkhorn distances: Lightspeed computation of optimal transport</text></passage><passage><infon key="fpage">18661</infon><infon key="lpage">18673</infon><infon key="name_0">surname:Khosla;given-names:P.</infon><infon key="name_1">surname:Teterwak;given-names:P.</infon><infon key="name_2">surname:Wang;given-names:C.</infon><infon key="name_3">surname:Sarna;given-names:A.</infon><infon key="name_4">surname:Tian;given-names:Y.</infon><infon key="name_5">surname:Isola;given-names:P.</infon><infon key="name_6">surname:Maschinot;given-names:A.</infon><infon key="name_7">surname:Liu;given-names:C.</infon><infon key="name_8">surname:Krishnan;given-names:D.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2020</infon><offset>54835</offset><text>Supervised contrastive learning</text></passage><passage><infon key="fpage">1</infon><infon key="name_0">surname:Maurício;given-names:J.</infon><infon key="name_1">surname:Domingues;given-names:I.</infon><infon key="pub-id_doi">10.1007/s10044-023-01206-3</infon><infon key="section_type">REF</infon><infon key="source">Pattern Anal. Appl.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2024</infon><offset>54867</offset><text>Distinguishing between Crohn’s disease and ulcerative colitis using deep learning models with interpretability</text></passage><passage><infon key="fpage">e193963</infon><infon key="name_0">surname:Stidham;given-names:R.W.</infon><infon key="name_1">surname:Liu;given-names:W.</infon><infon key="name_2">surname:Bishu;given-names:S.</infon><infon key="name_3">surname:Rice;given-names:M.D.</infon><infon key="name_4">surname:Higgins;given-names:P.D.</infon><infon key="name_5">surname:Zhu;given-names:J.</infon><infon key="name_6">surname:Nallamothu;given-names:B.K.</infon><infon key="name_7">surname:Waljee;given-names:A.K.</infon><infon key="pub-id_doi">10.1001/jamanetworkopen.2019.3963</infon><infon key="pub-id_pmid">31099869</infon><infon key="section_type">REF</infon><infon key="source">JAMA Netw. Open</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2019</infon><offset>54980</offset><text>Performance of a deep learning model vs human reviewers in grading endoscopic disease severity of patients with ulcerative colitis</text></passage><passage><infon key="fpage">2818</infon><infon key="lpage">2826</infon><infon key="name_0">surname:Szegedy;given-names:C.</infon><infon key="name_1">surname:Vanhoucke;given-names:V.</infon><infon key="name_2">surname:Ioffe;given-names:S.</infon><infon key="name_3">surname:Shlens;given-names:J.</infon><infon key="name_4">surname:Wojna;given-names:Z.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>55111</offset><text>Rethinking the inception architecture for computer vision</text></passage><passage><infon key="fpage">749</infon><infon key="lpage">756</infon><infon key="name_0">surname:Klang;given-names:E.</infon><infon key="name_1">surname:Grinman;given-names:A.</infon><infon key="name_2">surname:Soffer;given-names:S.</infon><infon key="name_3">surname:Margalit Yehuda;given-names:R.</infon><infon key="name_4">surname:Barzilay;given-names:O.</infon><infon key="name_5">surname:Amitai;given-names:M.M.</infon><infon key="name_6">surname:Konen;given-names:E.</infon><infon key="name_7">surname:Ben-Horin;given-names:S.</infon><infon key="name_8">surname:Eliakim;given-names:R.</infon><infon key="name_9">surname:Barash;given-names:Y.</infon><infon key="pub-id_doi">10.1093/ecco-jcc/jjaa234</infon><infon key="pub-id_pmid">33216853</infon><infon key="section_type">REF</infon><infon key="source">J. Crohn’s Colitis</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2021</infon><offset>55169</offset><text>Automated detection of Crohn’s disease intestinal strictures on capsule endoscopy images using deep neural networks</text></passage><passage><infon key="fpage">6105</infon><infon key="lpage">6114</infon><infon key="name_0">surname:Tan;given-names:M.</infon><infon key="name_1">surname:Le;given-names:Q.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Machine Learning</infon><infon key="type">ref</infon><offset>55287</offset><text>Efficientnet: Rethinking model scaling for convolutional neural networks</text></passage><passage><infon key="fpage">24771</infon><infon key="name_0">surname:Shah;given-names:S.A.</infon><infon key="name_1">surname:Taj;given-names:I.</infon><infon key="name_2">surname:Usman;given-names:S.M.</infon><infon key="name_3">surname:Hassan Shah;given-names:S.N.</infon><infon key="name_4">surname:Imran;given-names:A.S.</infon><infon key="name_5">surname:Khalid;given-names:S.</infon><infon key="pub-id_doi">10.1038/s41598-024-75901-4</infon><infon key="pub-id_pmid">39433818</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2024</infon><offset>55360</offset><text>A hybrid approach of vision transformers and CNNs for detection of ulcerative colitis</text></passage><passage><infon key="fpage">157</infon><infon key="lpage">171</infon><infon key="name_0">surname:Polat;given-names:G.</infon><infon key="name_1">surname:Ergenc;given-names:I.</infon><infon key="name_2">surname:Kani;given-names:H.T.</infon><infon key="name_3">surname:Alahdab;given-names:Y.O.</infon><infon key="name_4">surname:Atug;given-names:O.</infon><infon key="name_5">surname:Temizel;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Annual Conference on Medical Image Understanding and Analysis</infon><infon key="type">ref</infon><infon key="year">2022</infon><offset>55446</offset><text>Class distance weighted cross-entropy loss for ulcerative colitis severity estimation</text></passage><passage><infon key="fpage">2477</infon><infon key="lpage">2497</infon><infon key="name_0">surname:Malik;given-names:H.</infon><infon key="name_1">surname:Naeem;given-names:A.</infon><infon key="name_2">surname:Sadeghi-Niaraki;given-names:A.</infon><infon key="name_3">surname:Naqvi;given-names:R.A.</infon><infon key="name_4">surname:Lee;given-names:S.W.</infon><infon key="pub-id_doi">10.1007/s40747-023-01271-5</infon><infon key="section_type">REF</infon><infon key="source">Complex Intell. Syst.</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2024</infon><offset>55532</offset><text>Multi-classification deep learning models for detection of ulcerative colitis, polyps, and dyed-lifted polyps using wireless capsule endoscopy images</text></passage><passage><infon key="fpage">75</infon><infon key="lpage">81</infon><infon key="name_0">surname:Brodersen;given-names:J.B.</infon><infon key="name_1">surname:Jensen;given-names:M.D.</infon><infon key="name_2">surname:Leenhardt;given-names:R.</infon><infon key="name_3">surname:Kjeldsen;given-names:J.</infon><infon key="name_4">surname:Histace;given-names:A.</infon><infon key="name_5">surname:Knudsen;given-names:T.</infon><infon key="name_6">surname:Dray;given-names:X.</infon><infon key="pub-id_doi">10.1093/ecco-jcc/jjad131</infon><infon key="pub-id_pmid">37527554</infon><infon key="section_type">REF</infon><infon key="source">J. Crohn’s Colitis</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2024</infon><offset>55682</offset><text>Artificial intelligence-assisted analysis of pan-enteric capsule endoscopy in patients with suspected Crohn’s disease: A study on diagnostic performance</text></passage><passage><infon key="fpage">680</infon><infon key="lpage">689</infon><infon key="name_0">surname:Das;given-names:A.</infon><infon key="name_1">surname:Shukla;given-names:T.</infon><infon key="name_2">surname:Tomita;given-names:N.</infon><infon key="name_3">surname:Richards;given-names:R.</infon><infon key="name_4">surname:Vidis;given-names:L.</infon><infon key="name_5">surname:Ren;given-names:B.</infon><infon key="name_6">surname:Hassanpour;given-names:S.</infon><infon key="pub-id_doi">10.1016/j.ajpath.2024.12.010</infon><infon key="pub-id_pmid">39800054</infon><infon key="section_type">REF</infon><infon key="source">Am. J. Pathol.</infon><infon key="type">ref</infon><infon key="volume">195</infon><infon key="year">2025</infon><offset>55837</offset><text>Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology</text></passage><passage><infon key="fpage">101733</infon><infon key="name_0">surname:Guo;given-names:X.</infon><infon key="name_1">surname:Yuan;given-names:Y.</infon><infon key="pub-id_doi">10.1016/j.media.2020.101733</infon><infon key="pub-id_pmid">32574987</infon><infon key="section_type">REF</infon><infon key="source">Med. Image Anal.</infon><infon key="type">ref</infon><infon key="volume">64</infon><infon key="year">2020</infon><offset>55957</offset><text>Semi-supervised WCE image classification with adaptive aggregated attention</text></passage><passage><infon key="fpage">106174</infon><infon key="name_0">surname:Muruganantham;given-names:P.K.</infon><infon key="name_1">surname:Balakrishnan;given-names:S.M.</infon><infon key="pub-id_doi">10.1016/j.rineng.2025.106174</infon><infon key="section_type">REF</infon><infon key="source">Results Eng.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2025</infon><offset>56033</offset><text>Uncertainty-driven active learning in a deep semi-supervised framework for WCE image classification</text></passage><passage><infon key="fpage">2822</infon><infon key="lpage">2833</infon><infon key="name_0">surname:Lazo;given-names:J.F.</infon><infon key="name_1">surname:Rosa;given-names:B.</infon><infon key="name_2">surname:Catellani;given-names:M.</infon><infon key="name_3">surname:Fontana;given-names:M.</infon><infon key="name_4">surname:Mistretta;given-names:F.A.</infon><infon key="name_5">surname:Musi;given-names:G.</infon><infon key="name_6">surname:De Cobelli;given-names:O.</infon><infon key="name_7">surname:de Mathelin;given-names:M.</infon><infon key="name_8">surname:De Momi;given-names:E.</infon><infon key="pub-id_doi">10.1109/TBME.2023.3265679</infon><infon key="pub-id_pmid">37037233</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Biomed. Eng.</infon><infon key="type">ref</infon><infon key="volume">70</infon><infon key="year">2023</infon><offset>56133</offset><text>Semi-supervised bladder tissue classification in multi-domain endoscopic images</text></passage><passage><infon key="fpage">2342</infon><infon key="lpage">2353</infon><infon key="name_0">surname:Wang;given-names:Y.</infon><infon key="name_1">surname:Ni;given-names:H.</infon><infon key="name_2">surname:Zhou;given-names:J.</infon><infon key="name_3">surname:Liu;given-names:L.</infon><infon key="name_4">surname:Lin;given-names:J.</infon><infon key="name_5">surname:Yin;given-names:M.</infon><infon key="name_6">surname:Gao;given-names:J.</infon><infon key="name_7">surname:Zhu;given-names:S.</infon><infon key="name_8">surname:Yin;given-names:Q.</infon><infon key="name_9">surname:Zhu;given-names:J.</infon><infon key="pub-id_doi">10.1007/s10278-024-01123-9</infon><infon key="pub-id_pmid">38653910</infon><infon key="section_type">REF</infon><infon key="source">J. Imaging Inform. Med.</infon><infon key="type">ref</infon><infon key="volume">37</infon><infon key="year">2024</infon><offset>56213</offset><text>A Semi-Supervised learning framework for classifying colorectal neoplasia based on the NICE classification</text></passage><passage><infon key="fpage">631</infon><infon key="lpage">640</infon><infon key="name_0">surname:Golhar;given-names:M.</infon><infon key="name_1">surname:Bobrow;given-names:T.L.</infon><infon key="name_2">surname:Khoshknab;given-names:M.P.</infon><infon key="name_3">surname:Jit;given-names:S.</infon><infon key="name_4">surname:Ngamruengphong;given-names:S.</infon><infon key="name_5">surname:Durr;given-names:N.J.</infon><infon key="pub-id_doi">10.1109/ACCESS.2020.3047544</infon><infon key="pub-id_pmid">33747680</infon><infon key="section_type">REF</infon><infon key="source">IEEE Access</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2020</infon><offset>56320</offset><text>Improving colonoscopy lesion classification using semi-supervised deep learning</text></passage><passage><infon key="name_0">surname:Asano;given-names:Y.M.</infon><infon key="name_1">surname:Rupprecht;given-names:C.</infon><infon key="name_2">surname:Vedaldi;given-names:A.</infon><infon key="pub-id_arxiv">1911.05371</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>56400</offset><text>Self-labelling via simultaneous clustering and representation learning</text></passage><passage><infon key="fpage">1431</infon><infon key="lpage">1439</infon><infon key="name_0">surname:Polat;given-names:G.</infon><infon key="name_1">surname:Kani;given-names:H.T.</infon><infon key="name_2">surname:Ergenc;given-names:I.</infon><infon key="name_3">surname:Ozen Alahdab;given-names:Y.</infon><infon key="name_4">surname:Temizel;given-names:A.</infon><infon key="name_5">surname:Atug;given-names:O.</infon><infon key="pub-id_doi">10.1093/ibd/izac226</infon><infon key="pub-id_pmid">36382800</infon><infon key="section_type">REF</infon><infon key="source">Inflamm. Bowel Dis.</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2023</infon><offset>56471</offset><text>Improving the computer-aided estimation of ulcerative colitis severity according to mayo endoscopic score by using regression-based deep learning</text></passage><passage><infon key="name_0">surname:Dosovitskiy;given-names:A.</infon><infon key="name_1">surname:Beyer;given-names:L.</infon><infon key="name_2">surname:Kolesnikov;given-names:A.</infon><infon key="name_3">surname:Weissenborn;given-names:D.</infon><infon key="name_4">surname:Zhai;given-names:X.</infon><infon key="name_5">surname:Unterthiner;given-names:T.</infon><infon key="name_6">surname:Dehghani;given-names:M.</infon><infon key="name_7">surname:Minderer;given-names:M.</infon><infon key="name_8">surname:Heigold;given-names:G.</infon><infon key="name_9">surname:Gelly;given-names:S.</infon><infon key="pub-id_arxiv">2010.11929</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>56617</offset><text>An image is worth 16×16 words: Transformers for image recognition at scale</text></passage><passage><infon key="fpage">15619</infon><infon key="lpage">15629</infon><infon key="name_0">surname:Assran;given-names:M.</infon><infon key="name_1">surname:Duval;given-names:Q.</infon><infon key="name_2">surname:Misra;given-names:I.</infon><infon key="name_3">surname:Bojanowski;given-names:P.</infon><infon key="name_4">surname:Vincent;given-names:P.</infon><infon key="name_5">surname:Rabbat;given-names:M.</infon><infon key="name_6">surname:LeCun;given-names:Y.</infon><infon key="name_7">surname:Ballas;given-names:N.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>56693</offset><text>Self-supervised learning from images with a joint-embedding predictive architecture</text></passage><passage><infon key="fpage">248</infon><infon key="lpage">255</infon><infon key="name_0">surname:Deng;given-names:J.</infon><infon key="name_1">surname:Dong;given-names:W.</infon><infon key="name_2">surname:Socher;given-names:R.</infon><infon key="name_3">surname:Li;given-names:L.J.</infon><infon key="name_4">surname:Li;given-names:K.</infon><infon key="name_5">surname:Fei-Fei;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>56777</offset><text>Imagenet: A large-scale hierarchical image database</text></passage><passage><infon key="fpage">702</infon><infon key="lpage">703</infon><infon key="name_0">surname:Cubuk;given-names:E.D.</infon><infon key="name_1">surname:Zoph;given-names:B.</infon><infon key="name_2">surname:Shlens;given-names:J.</infon><infon key="name_3">surname:Le;given-names:Q.V.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</infon><infon key="type">ref</infon><offset>56829</offset><text>Randaugment: Practical automated data augmentation with a reduced search space</text></passage><passage><infon key="name_0">surname:Kinga;given-names:D.</infon><infon key="name_1">surname:Adam;given-names:J.B.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Learning Representations (ICLR)</infon><infon key="type">ref</infon><infon key="volume">Volume 5</infon><offset>56908</offset><text>A method for stochastic optimization</text></passage><passage><infon key="name_0">surname:Wang;given-names:Y.</infon><infon key="name_1">surname:Chen;given-names:H.</infon><infon key="name_2">surname:Heng;given-names:Q.</infon><infon key="name_3">surname:Hou;given-names:W.</infon><infon key="name_4">surname:Fan;given-names:Y.</infon><infon key="name_5">surname:Wu;given-names:Z.</infon><infon key="name_6">surname:Wang;given-names:J.</infon><infon key="name_7">surname:Savvides;given-names:M.</infon><infon key="name_8">surname:Shinozaki;given-names:T.</infon><infon key="name_9">surname:Raj;given-names:B.</infon><infon key="pub-id_arxiv">2205.07246</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2022</infon><offset>56945</offset><text>Freematch: Self-adaptive thresholding for semi-supervised learning</text></passage><passage><infon key="name_0">surname:Chen;given-names:H.</infon><infon key="name_1">surname:Tao;given-names:R.</infon><infon key="name_2">surname:Fan;given-names:Y.</infon><infon key="name_3">surname:Wang;given-names:Y.</infon><infon key="name_4">surname:Wang;given-names:J.</infon><infon key="name_5">surname:Schiele;given-names:B.</infon><infon key="name_6">surname:Xie;given-names:X.</infon><infon key="name_7">surname:Raj;given-names:B.</infon><infon key="name_8">surname:Savvides;given-names:M.</infon><infon key="pub-id_arxiv">2301.10921</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2023</infon><offset>57012</offset><text>Softmatch: Addressing the quantity-quality trade-off in semi-supervised learning</text></passage><passage><infon key="fpage">189</infon><infon key="lpage">228</infon><infon key="name_0">surname:DiCiccio;given-names:T.J.</infon><infon key="name_1">surname:Efron;given-names:B.</infon><infon key="pub-id_doi">10.1214/ss/1032280214</infon><infon key="section_type">REF</infon><infon key="source">Stat. Sci.</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">1996</infon><offset>57093</offset><text>Bootstrap confidence intervals</text></passage><passage><infon key="fpage">36</infon><infon key="lpage">42</infon><infon key="name_0">surname:Aberson;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">J. Artic. Support Null Hypothesis</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2002</infon><offset>57124</offset><text>Interpreting Null Results: Improving Presentation and Conclusions with Confidence Intervals</text></passage><passage><infon key="fpage">591</infon><infon key="lpage">605</infon><infon key="name_0">surname:Nakagawa;given-names:S.</infon><infon key="name_1">surname:Cuthill;given-names:I.C.</infon><infon key="pub-id_doi">10.1111/j.1469-185X.2007.00027.x</infon><infon key="pub-id_pmid">17944619</infon><infon key="section_type">REF</infon><infon key="source">Biol. Rev.</infon><infon key="type">ref</infon><infon key="volume">82</infon><infon key="year">2007</infon><offset>57216</offset><text>Effect size, confidence interval and statistical significance: A practical guide for biologists</text></passage><passage><infon key="fpage">770</infon><infon key="lpage">778</infon><infon key="name_0">surname:He;given-names:K.</infon><infon key="name_1">surname:Zhang;given-names:X.</infon><infon key="name_2">surname:Ren;given-names:S.</infon><infon key="name_3">surname:Sun;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</infon><infon key="type">ref</infon><offset>57312</offset><text>Deep residual learning for image recognition</text></passage><passage><infon key="fpage">2579</infon><infon key="lpage">2605</infon><infon key="name_0">surname:Maaten;given-names:L.v.d.</infon><infon key="name_1">surname:Hinton;given-names:G.</infon><infon key="section_type">REF</infon><infon key="source">J. Mach. Learn. Res.</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2008</infon><offset>57357</offset><text>Visualizing data using t-SNE</text></passage><passage><infon key="fpage">2825</infon><infon key="lpage">2830</infon><infon key="name_0">surname:Pedregosa;given-names:F.</infon><infon key="name_1">surname:Varoquaux;given-names:G.</infon><infon key="name_2">surname:Gramfort;given-names:A.</infon><infon key="name_3">surname:Michel;given-names:V.</infon><infon key="name_4">surname:Thirion;given-names:B.</infon><infon key="name_5">surname:Grisel;given-names:O.</infon><infon key="name_6">surname:Blondel;given-names:M.</infon><infon key="name_7">surname:Prettenhofer;given-names:P.</infon><infon key="name_8">surname:Weiss;given-names:R.</infon><infon key="name_9">surname:Dubourg;given-names:V.</infon><infon key="section_type">REF</infon><infon key="source">J. Mach. Learn. Res.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2011</infon><offset>57386</offset><text>Scikit-learn: Machine learning in Python</text></passage><passage><infon key="fpage">8050</infon><infon key="lpage">8058</infon><infon key="name_0">surname:Saito;given-names:K.</infon><infon key="name_1">surname:Kim;given-names:D.</infon><infon key="name_2">surname:Sclaroff;given-names:S.</infon><infon key="name_3">surname:Darrell;given-names:T.</infon><infon key="name_4">surname:Saenko;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the IEEE/CVF International Conference on Computer Vision</infon><infon key="type">ref</infon><offset>57427</offset><text>Semi-supervised domain adaptation via minimax entropy</text></passage><passage><infon key="name_0">surname:Berthelot;given-names:D.</infon><infon key="name_1">surname:Roelofs;given-names:R.</infon><infon key="name_2">surname:Sohn;given-names:K.</infon><infon key="name_3">surname:Carlini;given-names:N.</infon><infon key="name_4">surname:Kurakin;given-names:A.</infon><infon key="pub-id_arxiv">2106.04732</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2021</infon><offset>57481</offset><text>Adamatch: A unified approach to semi-supervised learning and domain adaptation</text></passage><passage><infon key="comment">
in press
</infon><infon key="name_0">surname:Matsui;given-names:I.</infon><infon key="name_1">surname:Matsumoto;given-names:A.</infon><infon key="name_2">surname:Imai;given-names:A.</infon><infon key="name_3">surname:Okushima;given-names:H.</infon><infon key="name_4">surname:Niioka;given-names:H.</infon><infon key="name_5">surname:Abe;given-names:M.</infon><infon key="name_6">surname:Tamai;given-names:N.</infon><infon key="name_7">surname:Nagasu;given-names:H.</infon><infon key="name_8">surname:Kanda;given-names:E.</infon><infon key="name_9">surname:Uchino;given-names:E.</infon><infon key="pub-id_doi">10.1038/s41746-025-02160-6</infon><infon key="section_type">REF</infon><infon key="source">npj Digit. Med.</infon><infon key="type">ref</infon><infon key="year">2025</infon><offset>57560</offset><text>Domain-adaptive semi-supervised learning for efficient rare pathological lesion detection with minimal annotation</text></passage><passage><infon key="fpage">25956</infon><infon key="lpage">25967</infon><infon key="name_0">surname:Saito;given-names:K.</infon><infon key="name_1">surname:Kim;given-names:D.</infon><infon key="name_2">surname:Saenko;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Adv. Neural Inf. Process. Syst.</infon><infon key="type">ref</infon><infon key="volume">34</infon><infon key="year">2021</infon><offset>57674</offset><text>Openmatch: Open-set semi-supervised learning with open-set consistency regularization</text></passage><passage><infon key="file">bioengineering-13-00008-g001.jpg</infon><infon key="id">bioengineering-13-00008-f001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>57760</offset><text>A schematic overview of the proposed SACSSL. The framework comprises a visual encoder, a prediction head, and a projection head. These components are integrated with two complementary modules: a semi-supervised learning module and a subclass-aware contrastive module. See main text for a detailed explanation.</text></passage><passage><infon key="file">bioengineering-13-00008-g002.jpg</infon><infon key="id">bioengineering-13-00008-f002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>58070</offset><text>A schematic illustration of the subclass-aware contrastive module. The module processes embeddings from two strong augmentations ( and , shown as solid and dashed shapes, respectively) of each image. It first separates embeddings into confident and uncertain groups based on pseudo-label confidence. Confident embeddings are assigned to online-updated subclass prototypes (numbered squares) to form subclasses, where black dashed circles indicate embeddings belonging to the same subclass. Subclass-level contrastive learning then optimizes these confident embeddings by attracting intra-subclass embeddings while repelling inter-subclass ones. Meanwhile, instance-level contrastive learning optimizes uncertain embeddings to repel samples from different images, where gray rectangles enclose augmentation pairs from the same original image. Together, these two components form the subclass-aware contrastive loss.</text></passage><passage><infon key="file">bioengineering-13-00008-g003.jpg</infon><infon key="id">bioengineering-13-00008-f003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>58985</offset><text>Comparison of the t-SNE visualization of the embedded feature distributions on the Daping test set between FixMatch and the proposed SACSSL using t-SNE. Each color denotes one of the 3 classes.</text></passage><passage><infon key="file">bioengineering-13-00008-t001.xml</infon><infon key="id">bioengineering-13-00008-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>59179</offset><text>Common symbols used in Section 3.</text></passage><passage><infon key="file">bioengineering-13-00008-t001.xml</infon><infon key="id">bioengineering-13-00008-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Symbol&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Meaning&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sec.&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm238&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Labeled image and the corresponding ground truth label&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm239&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Unlabeled image&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm240&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Visual encoder&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm241&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Prediction head&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm242&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;h&lt;/mml:mi&gt;&lt;mml:mi&gt;ϕ&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Projection head&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm243&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;y&lt;/mml:mi&gt;&lt;mml:mo&gt;|&lt;/mml:mo&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo&gt;;&lt;/mml:mo&gt;&lt;mml:mi&gt;θ&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Model’s predicted distribution over classes&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic toggle=&quot;yes&quot;&gt;z&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Projected representation in embedding space&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm244&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;B&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;B&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Labeled and unlabeled subsets in a data batch&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm245&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;B&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Number of labeled and unlabeled samples in a data batch&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm246&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;w&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;·&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Weak augmentation&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm247&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;·&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;First strong augmentation&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm248&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;A&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;g&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;·&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Second strong augmentation&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm249&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;·&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Soft pseudo-label&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot1-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.1&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm250&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;^&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;·&lt;/mml:mo&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hard pseudo-label&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot1-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.1&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm251&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;B&lt;/mml:mi&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Multi-view batch&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm252&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;x&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Strongly augmented view and its soft pseudo-label&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm253&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;T&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Confidence threshold for separating confident and uncertain samples&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm254&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;I&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Index set of confident samples&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm255&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;I&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Index set of uncertain samples&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm256&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;I&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Index set of confident samples predicted as class &lt;italic toggle=&quot;yes&quot;&gt;c&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm257&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic toggle=&quot;yes&quot;&gt;k&lt;/italic&gt;-th prototype of class &lt;italic toggle=&quot;yes&quot;&gt;c&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm258&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sample-to-prototype assignment probability matrix for class &lt;italic toggle=&quot;yes&quot;&gt;c&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm259&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;Z&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Embedding matrix for confident samples of class &lt;italic toggle=&quot;yes&quot;&gt;c&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm260&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;P&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Prototype matrix containing &lt;italic toggle=&quot;yes&quot;&gt;K&lt;/italic&gt; prototypes for class &lt;italic toggle=&quot;yes&quot;&gt;c&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;xref rid=&quot;sec3dot2dot2-bioengineering-13-00008&quot; ref-type=&quot;sec&quot;&gt;Section 3.2.2&lt;/xref&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>59213</offset><text>Symbol	Meaning	Sec.	 		Labeled image and the corresponding ground truth label	Section 3	 		Unlabeled image	Section 3	 		Visual encoder	Section 3	 		Prediction head	Section 3	 		Projection head	Section 3	 		Model’s predicted distribution over classes	Section 3	 	z	Projected representation in embedding space	Section 3	 		Labeled and unlabeled subsets in a data batch	Section 3	 		Number of labeled and unlabeled samples in a data batch	Section 3	 		Weak augmentation	Section 3	 		First strong augmentation	Section 3	 		Second strong augmentation	Section 3	 		Soft pseudo-label	Section 3.1	 		Hard pseudo-label	Section 3.1	 		Multi-view batch	Section 3.2	 		Strongly augmented view and its soft pseudo-label	Section 3.2	 		Confidence threshold for separating confident and uncertain samples	Section 3.2	 		Index set of confident samples	Section 3.2	 		Index set of uncertain samples	Section 3.2	 		Index set of confident samples predicted as class c	Section 3.2.2	 		k-th prototype of class c	Section 3.2.2	 		Sample-to-prototype assignment probability matrix for class c	Section 3.2.2	 		Embedding matrix for confident samples of class c	Section 3.2.2	 		Prototype matrix containing K prototypes for class c	Section 3.2.2	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t002.xml</infon><infon key="id">bioengineering-13-00008-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>60440</offset><text>Quantitative comparison with SOTA semi-supervised learning methods on the Daping dataset. The best results are highlighted in bold. LDP: percentage of labeled data; UDP: percentage of unlabeled data.</text></passage><passage><infon key="file">bioengineering-13-00008-t002.xml</infon><infon key="id">bioengineering-13-00008-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;Method&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Upper-Bound&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;96.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FixMatch &lt;xref rid=&quot;B18-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;18&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;71.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FreeMatch &lt;xref rid=&quot;B55-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;55&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CCSSL &lt;xref rid=&quot;B25-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;25&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;95.0&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;SoftMatch &lt;xref rid=&quot;B56-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;56&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;SA-FixMatch &lt;xref rid=&quot;B21-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;Ours&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>60640</offset><text>Method	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	Upper-Bound	100	0	94.0	78.4	96.4	80.8	 	Baseline	20	0	91.0	74.2	93.9	75.5	 	FixMatch 	20	80	92.0	71.7	93.9	74.4	 	FreeMatch 	20	80	92.2	73.8	94.2	76.1	 	CCSSL 	20	80	92.7	76.0	95.0	78.2	 	SoftMatch 	20	80	92.3	74.9	93.9	77.1	 	SA-FixMatch 	20	80	91.7	74.5	94.4	76.5	 	Ours	20	80	93.2	76.8	94.9	80.1	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t003.xml</infon><infon key="id">bioengineering-13-00008-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>61071</offset><text>Quantitative comparison with SOTA semi-supervised learning methods on the LIMUC dataset. The best results are highlighted in bold. LDP: percentage of labeled data; UDP: percentage of unlabeled data.</text></passage><passage><infon key="file">bioengineering-13-00008-t003.xml</infon><infon key="id">bioengineering-13-00008-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;Method&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Upper-Bound&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;79.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;72.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;62.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;89.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;63.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FixMatch &lt;xref rid=&quot;B18-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;18&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;65.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;66.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FreeMatch &lt;xref rid=&quot;B55-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;55&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;68.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;68.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CCSSL &lt;xref rid=&quot;B25-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;25&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;68.9&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;91.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;68.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;SoftMatch &lt;xref rid=&quot;B56-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;56&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;67.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;67.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;SA-Fixmatch &lt;xref rid=&quot;B21-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;66.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;67.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;Ours&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.4&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;67.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;68.9&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>61270</offset><text>Method	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	Upper-Bound	100	0	79.6	74.4	92.2	73.4	 	Baseline	20	0	72.1	62.3	89.2	63.2	 	FixMatch 	20	80	75.1	65.9	90.4	66.9	 	FreeMatch 	20	80	75.2	68.2	90.8	68.7	 	CCSSL 	20	80	75.9	68.9	91.2	68.0	 	SoftMatch 	20	80	76.1	67.4	91.1	67.3	 	SA-Fixmatch 	20	80	75.7	66.8	90.3	67.8	 	Ours	20	80	76.4	67.7	91.0	68.9	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t004.xml</infon><infon key="id">bioengineering-13-00008-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>61701</offset><text>Performance of our method on the Daping dataset under different percentages of labeled data (%). The best results are highlighted in bold font. LDP: labeled data percentage; UDP: unlabeled data percentage.</text></passage><passage><infon key="file">bioengineering-13-00008-t004.xml</infon><infon key="id">bioengineering-13-00008-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;Method&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Upper-Bound&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;96.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;85.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;70.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;86.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;65.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ours&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;95&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;90.3&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;68.5&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;92.4&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;71.3&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;89.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;71.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ours&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;92.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;75.0&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;94.6&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;77.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ours&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;94.9&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;30&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ours&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;30&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;70&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.4&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;77.4&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;95.5&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;79.8&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>61907</offset><text>Method	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	Upper-Bound	100	0	94.0	78.4	96.4	80.8	 	Baseline	5	0	85.6	70.8	86.8	65.3	 	Ours	5	95	90.3	68.5	92.4	71.3	 	Baseline	10	0	89.2	73.5	92.2	71.1	 	Ours	10	90	92.2	75.0	94.6	77.1	 	Baseline	20	0	91.0	74.2	93.9	75.5	 	Ours	20	80	93.2	76.8	94.9	80.1	 	Baseline	30	0	91.5	73.0	94.1	74.9	 	Ours	30	70	93.4	77.4	95.5	79.8	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t005.xml</infon><infon key="id">bioengineering-13-00008-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>62346</offset><text>Results on validating the effectiveness of different losses. The best results are highlighted in bold font. LDP: labeled data percentage; UDP: unlabeled data percentage.</text></passage><passage><infon key="file">bioengineering-13-00008-t005.xml</infon><infon key="id">bioengineering-13-00008-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;Method&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Loss Functions&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm261&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;bold-script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;s&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm262&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;bold-script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm263&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;bold-script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;unc&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm264&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;bold-script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;conf&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Upper-Bound&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;96.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm265&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;71.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm266&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm267&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;script&quot;&gt;L&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;o&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ours&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;✓&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;94.9&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>62516</offset><text>Method	Loss Functions	Percentage (%)	Metrics (%)	 						 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	Upper-Bound	✓				100	0	94.0	78.4	96.4	80.8	 	Baseline	✓				20	0	91.0	74.2	93.9	75.5	 		✓	✓			20	80	92.0	71.1	93.9	74.4	 		✓	✓	✓		20	80	92.4	75.3	94.7	77.3	 		✓	✓		✓	20	80	92.5	73.1	94.4	75.9	 	Ours	✓	✓	✓	✓	20	80	93.2	76.8	94.9	80.1	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t006.xml</infon><infon key="id">bioengineering-13-00008-t006</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>62922</offset><text>Results on investigating the influence of the confidence threshold . The best results are highlighted in bold. LDP: percentage of labeled data; UDP: percentage of unlabeled data.</text></passage><passage><infon key="file">bioengineering-13-00008-t006.xml</infon><infon key="id">bioengineering-13-00008-t006</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;
&lt;inline-formula&gt;
&lt;mml:math id=&quot;mm269&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mstyle mathvariant=&quot;bold&quot;&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;T&lt;/mml:mi&gt;&lt;mml:mi mathvariant=&quot;bold-italic&quot;&gt;conf&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mstyle&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;
&lt;/inline-formula&gt;
&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;78.5&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;95.3&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;79.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;95.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.95&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.5&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>63101</offset><text>	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	0.6	20	80	92.1	78.5	94.8	78.8	 	0.7	20	80	93.0	77.9	95.3	79.7	 	0.8	20	80	92.9	76.4	95.1	78.7	 	0.9	20	80	93.2	76.8	94.9	80.1	 	0.95	20	80	92.3	74.6	94.0	77.5	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t007.xml</infon><infon key="id">bioengineering-13-00008-t007</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>63381</offset><text>Results on investigating the influence of the number of prototypes per class K. The best results are highlighted in bold. LDP: percentage of labeled data; UDP: percentage of unlabeled data.</text></passage><passage><infon key="file">bioengineering-13-00008-t007.xml</infon><infon key="id">bioengineering-13-00008-t007</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;
&lt;italic toggle=&quot;yes&quot;&gt;K&lt;/italic&gt;
&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;95.0&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.2&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>63571</offset><text>K	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	2	20	80	92.7	73.3	94.7	76.2	 	3	20	80	93.2	76.8	94.9	80.1	 	4	20	80	92.7	74.6	94.9	77.3	 	5	20	80	92.5	73.7	94.7	76.4	 	6	20	80	92.9	74.2	95.0	77.2	 	</text></passage><passage><infon key="file">bioengineering-13-00008-t008.xml</infon><infon key="id">bioengineering-13-00008-t008</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>63841</offset><text>Results on investigating the influence of architecture of the visual encoder . The best results are highlighted in bold. LDP: percentage of labeled data; UDP: percentage of unlabeled data.</text></passage><passage><infon key="file">bioengineering-13-00008-t008.xml</infon><infon key="id">bioengineering-13-00008-t008</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; colspan=&quot;1&quot;&gt;Backbone&lt;/th&gt;&lt;th colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot;&gt;Percentage (%)&lt;/th&gt;&lt;th colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Metrics (%)&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
LDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
UDP
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Accuracy
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Sensitivity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
Specificity
&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
F1-Score
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ResNet-50 &lt;xref rid=&quot;B60-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;60&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;91.5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;93.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77.6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;EfficientNet-B5 &lt;xref rid=&quot;B37-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;37&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;92.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;72.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ViT-B &lt;xref rid=&quot;B50-bioengineering-13-00008&quot; ref-type=&quot;bibr&quot;&gt;50&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-right:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;93.2&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;76.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;94.9&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;80.1&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>64030</offset><text>Backbone	Percentage (%)	Metrics (%)	 		 	LDP	 			 	UDP	 			 	Accuracy	 			 	Sensitivity	 			 	Specificity	 			 	F1-Score	 		 	ResNet-50 	20	80	91.5	76.6	93.8	77.6	 	EfficientNet-B5 	20	80	92.1	72.9	94.1	75.5	 	ViT-B 	20	80	93.2	76.8	94.9	80.1	 	</text></passage></document>
</collection>